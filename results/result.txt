
param_grid = {
	'clf__hidden_layer_sizes': [(50), (100), (50, 50), (100, 100)],
	'clf__learning_rate_init': [1, 0.1, 0.01, 0.001, 0.0001]
}

15.7min
[Parallel(n_jobs=7)]: Done  80 out of  80 | elapsed: 93.4min finished
Iteration 1, loss = 2.79200678
Validation score: 0.716431
Iteration 2, loss = 1.94847936
Validation score: 0.848057
Iteration 3, loss = 1.05389166
Validation score: 0.881625
Iteration 4, loss = 0.54788779
Validation score: 0.901060
Iteration 5, loss = 0.31937223
Validation score: 0.906360
Iteration 6, loss = 0.20593260
Validation score: 0.909011
Iteration 7, loss = 0.14298290
Validation score: 0.909894
Iteration 8, loss = 0.10495337
Validation score: 0.909894
Iteration 9, loss = 0.08058449
Validation score: 0.908127
Validation score did not improve more than tol=0.001000 for two consecutive epochs. Stopping.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> grid.best_params_
{'clf__hidden_layer_sizes': 100, 'clf__learning_rate_init': 0.001}
>>> import pandas as pd
>>> r = pd.DataFrame(grid.cv_results_)
/home/kleidl/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True
  warnings.warn(*warn_args, **warn_kwargs)
/home/kleidl/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True
  warnings.warn(*warn_args, **warn_kwargs)
/home/kleidl/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True
  warnings.warn(*warn_args, **warn_kwargs)
/home/kleidl/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True
  warnings.warn(*warn_args, **warn_kwargs)
/home/kleidl/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True
  warnings.warn(*warn_args, **warn_kwargs)
/home/kleidl/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True
  warnings.warn(*warn_args, **warn_kwargs)
>>> scores = np.array(r.mean_test_score)
>>> scores
array([0.28539862, 0.85884745, 0.88713099, 0.88518649, 0.86512286,
       0.36211773, 0.85009722, 0.88721937, 0.89075482, 0.87590596,
       0.06080962, 0.8020152 , 0.86096871, 0.87316599, 0.86335514,
       0.05683224, 0.80537387, 0.87095634, 0.87776206, 0.87493371])
>>> scores = scores.reshape(4, 5)
>>> scores
array([[0.28539862, 0.85884745, 0.88713099, 0.88518649, 0.86512286],
       [0.36211773, 0.85009722, 0.88721937, 0.89075482, 0.87590596],
       [0.06080962, 0.8020152 , 0.86096871, 0.87316599, 0.86335514],
       [0.05683224, 0.80537387, 0.87095634, 0.87776206, 0.87493371]])

>>> 
>>> print 'Done!'
Done!
>>> 
>>> print "Best cross-validation accuracy", grid.best_score_
Best cross-validation accuracy 0.8907548170408344
>>> print "Test best score", grid.score(twenty_test.data, twenty_test.target)
Test best score 0.8154540626659585
>>> print "Best parameters", grid.best_params_
Best parameters {'clf__hidden_layer_sizes': 100, 'clf__learning_rate_init': 0.001}
>>> 
>>> # In[15]:
... 
>>> # Performance of NB Classifier
... predicted = text_clf.predict(twenty_test.data)
>>> print "Accuracy:", accuracy_score(twenty_test.target, predicted)
Accuracy: 0.8154540626659585
>>> print "Macro F1:", f1_score(twenty_test.target, predicted, average='macro')  
Macro F1: 0.8080134525061737
>>> print "Micro F1:", f1_score(twenty_test.target, predicted, average='micro') 
Micro F1: 0.8154540626659585
>>> 

