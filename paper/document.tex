\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}


% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
% \acmDOI{10.475/123_4}

% ISBN
% \acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[UPDS-SoSe18]{Uni Passau - Data Science Seminar - SoSe18}{July 2018}{Passau, Germany}
\copyrightyear{2018}

\begin{document}
\title{Hyperparameter Study for Classical Feedforward Neural Networks on Text Data}

\author{Marius Kleidl}
\affiliation{%
  \institution{University of Passau}
  \city{Passau}
}
\email{kleidl01@gw.uni-passau.de}


% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{B. Trovato et al.}


\begin{abstract}
This paper provides a sample of a \LaTeX\ document which conforms,
somewhat loosely, to the formatting guidelines for
ACM SIG Proceedings.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
 \begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10010147.10010257.10010258.10010259.10010263</concept_id>
	<concept_desc>Computing methodologies~Supervised learning by classification</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10010147.10010257.10010293.10010294</concept_id>
	<concept_desc>Computing methodologies~Neural networks</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Supervised learning by classification}
\ccsdesc[500]{Computing methodologies~Neural networks}


\keywords{ACM proceedings, \LaTeX, text tagging}


\maketitle

\section{Introduction}

In Natural Language Processing application 

\section{Contribution}

In our experiment we train and evaluate the performance of multiple deep neural networks with different numbers of layers, numbers of neurons per layer and different learning rates.
This section describes the setup of our experiment, in particular the data set, the chosen feature extraction steps, the hyperparameters for our neural network and our evaluation method. The experiment is conducted using the machine learning software scikit-learn\cite{scikit-learn} in its version 0.19.1.

\subsection{Data Set}

The experiments are performed using the well-known 20Newsgroups\footnote{\href{http://qwone.com/~jason/20Newsgroups/}{http://qwone.com/$\sim$jason/20Newsgroups/}} data set. It contains 18846 postings in the English language which are nearly evenly distributed across 20 different newsgroups, as can be seen in Table~\ref{tab:groups}. Furthermore, the set has been split into a training set of 11314 postings and a testing set of 7532. This division is based upon the time of the posting\cite{sklearn-newsgroup}.

An example for a post's format is given in Figure~\ref{fig:post}. As one can see, the post contains a header and signature sections consisting of additional meta data, such as the sender's e-mail address and organization. To prevent our neural network from association this meta data with specific classes, we remove the headers and signatures from each post.

\begin{figure*}
	\label{fig:post}
	\begin{center}
		\begin{tabular}{c}
			\begin{lstlisting}[basicstyle=\footnotesize]
From: JC924@uacsc2.albany.edu
Subject: Why are our desktop fonts changing?
Organization: University at Albany, Albany NY 12222
X-Newsreader: NNR/VM S_1.3.2
Lines: 17

One of our users is having an unusual problem.  If she does an Alt/Tab to
a full-screen DOS program, when she goes back to Windows her desktop fonts
have changed.  If she goes back to a full-screen DOS program and then goes
back to Windows, the font has changed back to its default font.  It's not
a major problem (everything works and the font is legible), but it is
annoying.  Does anyone have any idea why this happens.  By the way, she
has a DEC 486D2LP machine.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Jeffrey M. Cohen                      Voice: 518-442-3510
Office for Research (AD 218)          Fax:   518-442-3560
The University at Albany              E-mail: JC924@uacsc2.albany.edu
State University of New York
1400 Washington Ave.
Albany, NY 12222
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
			\end{lstlisting}
		\end{tabular}
	\end{center}
	\caption{Postings example from the comp.os.ms-windows.misc newsgroup}
\end{figure*}

\begin{table}[]
	\centering
	\caption{Postings per newsgroup}
	\label{tab:groups}
	\begin{tabular}{c|c}
		\hline                      %inserts double horizontal lines
		Newsgroup & Number of postings \\ %[0.5ex]
		\hline
		rec.motorcycles & 996 \\
		comp.sys.mac.hardware & 963 \\
		talk.politics.misc & 775 \\
		soc.religion.christian & 997 \\
		comp.graphics & 973 \\
		sci.med & 990 \\
		talk.religion.misc & 628 \\
		comp.windows.x & 988 \\
		comp.sys.ibm.pc.hardware & 982 \\
		talk.politics.guns & 910 \\
		alt.atheism & 799 \\
		comp.os.ms-windows.misc & 985 \\
		sci.crypt & 991 \\
		sci.space & 987 \\
		misc.forsale & 975 \\
		rec.sport.hockey & 999 \\
		rec.sport.baseball & 994 \\
		sci.electronics & 984 \\
		rec.autos & 990 \\
		talk.politics.mideast & 940
	\end{tabular}
\end{table}

\subsection{Feature Extraction}

Since raw sequences of characters cannot be processed by neural networks, we need to represent our data in vector of fixed sizes. In order to achieve this, the text has been converted into the commonly used bag-of-words model after removing English stop words, such as "the" and "is". Our model only contains single words and not pair of words used next to each others\footnote{These pairs of words are commonly knows as bigrams and are used to keep information about the structure of sentences.}. Furthermore, the model does not discard words depending on their appearance of frequency. Every word used in the text is contained in the model, even if it only appears once.

Next, we normalize the entries in our bag-of-words representation. For classification words with a higher frequency of occurrence are usually less informative than specialized words which are more rarely used. Therefore, if we would use the frequency of occurrence for rating a word's importance, we will assign more specialized words a less important impact. This low rating causes that specialized words are considered as of less importance than general words, even though it's the opposite. To avoid this, we need to avoid that word's importance is based on its frequency of occurrence. This can be achieved by rating a word's impact based on its term frequency-inverse document frequency (TFIDF). Using this normalization, words with a high frequency will by considered of less importance.

\subsection{Deep Neural Network}

Our neural networks contains one or two hidden feed-forward layers consisting of 50 or 100 perceptrons. The learning rate is 1, 0.1, 0.001 or 0.0001. For the activation function we choose the rectified linear unit function (ReLu) as defined by $f(x) = max(0, x)$. This decision was based on previous work which showed the ReLu is able to provide better classification accuracy in supervised training than the hyperbolic tan function or the the logistic sigmoid function\cite{pmlr-v15-glorot11a}. The loss-function is optimized using the stochastic gradient descent optimizer Adam as proposed by Kingma, Diederik, and Jimmy Ba \cite{adam}. The L2 penalty paramter $alpha$ for regularization has been set to 0.0001.

Each neural network is trained until its accuracy stops to increase noticeably. For this purpose, 10\% of the training set will be split apart as a validation set. After each training iteration using the remaining 90\% the network's performance will be evaluated using the validation set. If the mean accuracy across all classes does not improve more than 0.1 percentage point for two iterations, the training will be stopped. 

\subsection{Evaluation}

The classifier's performance is measured using its mean accuracy. This is done by calculating the mean of the classifier's accuracy for each label.

In order to avoid that a classifier 

\section{Results}

\begin{figure}
	\centering
	\label{fig:heatmap}
	\includegraphics[width=9cm]{fig2.pdf}
	\caption{Mean accuracy for a classifier using different hyperparameters. The X-axis depicts te learning rate while the Y-axis show the number of hidden layers and number of perceptron per hidden layer.}
\end{figure}

\section{Conclusion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{document}

\end{document}
